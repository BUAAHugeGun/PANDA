{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "def widthN_to_bsN(x, N):\n",
    "    # x: (bs, c, h, w*N) -> (N*bs, c, h, w)\n",
    "    bs, c, h, w = x.shape\n",
    "    w = w // N\n",
    "    x = torch.stack(x.split(w, dim=-1), dim=1).view(-1, c, h, w)\n",
    "    return x\n",
    "\n",
    "def bsN_to_widthN(x, N):\n",
    "    # x: (N*bs, c, h, w) -> (bs, c, h, w*N)\n",
    "    bs, c, h, w = x.shape\n",
    "    bs = bs // N\n",
    "    x = torch.stack(x.split(N, dim=0)).permute(0, 2, 3, 1, 4).reshape(bs, c, h, -1)\n",
    "    return x\n",
    "\n",
    "def bsN_to_5dim(x, N):\n",
    "    # x: (N*bs, c, h, w) -> (bs, N, c, h, w)\n",
    "    bs, c, h, w = x.shape\n",
    "    bs = bs // N\n",
    "    x = torch.stack(x.split(N, dim=0))\n",
    "    return x\n",
    "\n",
    "\n",
    "class Resnet18(nn.Module):\n",
    "    def __init__(self, pretrain=True, classes=6, N=25):\n",
    "        super(Resnet18, self).__init__()\n",
    "        print(\"Using Network = resnet18 classifier\", classes)\n",
    "        self.N = N\n",
    "\n",
    "        model = torchvision.models.resnet18(pretrained=pretrain)\n",
    "        self.encoder = nn.Sequential(*list(model.children())[:-2])\n",
    "        feat_channel = list(model.children())[-1].in_features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feat_channel, classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.encoder(widthN_to_bsN(x, self.N))\n",
    "        return self.classifier(bsN_to_widthN(f, self.N))\n",
    "\n",
    "\n",
    "class Resnet18_asigm(nn.Module):\n",
    "    def __init__(self, pretrain=True, classes=6, N=25):\n",
    "        super(Resnet18_asigm, self).__init__()\n",
    "        print(\"Using Network = resnet18 + learned a (sigmoid)\")\n",
    "        self.N = N\n",
    "        self.classes = classes\n",
    "\n",
    "        model = torchvision.models.resnet18(pretrained=pretrain)\n",
    "        self.encoder = nn.Sequential(*list(model.children())[:-2])\n",
    "        feat_channel = list(model.children())[-1].in_features\n",
    "\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.penultimate = nn.Sequential(\n",
    "            nn.Linear(feat_channel, classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(feat_channel, classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.encoder(widthN_to_bsN(x, self.N))\n",
    "        f = self.gap(bsN_to_widthN(f, self.N))\n",
    "        p = self.penultimate(f)\n",
    "        a = self.final(f)\n",
    "        return (self.classes - 1) * (a * p).sum(dim=1).sigmoid()\n",
    "\n",
    "\n",
    "class Resnet18_afix(nn.Module):\n",
    "    def __init__(self, pretrain=True, classes=6, N=25):\n",
    "        super(Resnet18_afix, self).__init__()\n",
    "        print(\"Using Network = resnet18 + fixed a\")\n",
    "        self.N = N\n",
    "        self.classes = classes\n",
    "\n",
    "        model = torchvision.models.resnet18(pretrained=pretrain)\n",
    "        self.encoder = nn.Sequential(*list(model.children())[:-2])\n",
    "        feat_channel = list(model.children())[-1].in_features\n",
    "\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.penultimate = nn.Sequential(\n",
    "            nn.Linear(feat_channel, classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self.register_buffer('a', torch.arange(classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.encoder(widthN_to_bsN(x, self.N))\n",
    "        f = self.gap(bsN_to_widthN(f, self.N))\n",
    "        pred_softmax = self.penultimate(f)\n",
    "        pred_label = (pred_softmax * self.a).sum(dim=1)\n",
    "        return pred_label, pred_softmax\n",
    "\n",
    "\n",
    "class Resnet50_afix(nn.Module):\n",
    "    def __init__(self, pretrain=True, classes=6, N=25):\n",
    "        super(Resnet50_afix, self).__init__()\n",
    "        print(\"Using Network = resnet50 + fixed a\")\n",
    "        self.N = N\n",
    "        self.classes = classes\n",
    "\n",
    "        model = torchvision.models.resnet50(pretrained=pretrain)\n",
    "        self.encoder = nn.Sequential(*list(model.children())[:-2])\n",
    "        feat_channel = list(model.children())[-1].in_features\n",
    "\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.penultimate = nn.Sequential(\n",
    "            nn.Linear(feat_channel, classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self.register_buffer('a', torch.arange(classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.encoder(widthN_to_bsN(x, self.N))\n",
    "        f = self.gap(bsN_to_widthN(f, self.N))\n",
    "        pred_softmax = self.penultimate(f)\n",
    "        pred_label = (pred_softmax * self.a).sum(dim=1)\n",
    "        return pred_label, pred_softmax\n",
    "\n",
    "\n",
    "def get_model_by_name(name, **kwargs):\n",
    "    models = {\n",
    "        'res18': Resnet18,\n",
    "        'res18_asigm': Resnet18_asigm,\n",
    "        'res18_afix': Resnet18_afix,\n",
    "        'res50_afix': Resnet50_afix,\n",
    "    }\n",
    "    assert name in models\n",
    "    m = models[name]\n",
    "    return m(**kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip uninstall --yes scikit-image\n",
    "!pip install ../input/skimage0162/scikit_image-0.16.2-cp37-cp37m-manylinux1_x86_64.whl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import albumentations\n",
    "\n",
    "import skimage.io\n",
    "from skimage import transform\n",
    "\n",
    "sz = 256\n",
    "N = 64\n",
    "sN = 8\n",
    "scale_factor = 1\n",
    "\n",
    "\n",
    "def tile(img):\n",
    "    shape = img.shape\n",
    "    pad0, pad1 = (sz - shape[0] % sz) % sz, (sz - shape[1] % sz) % sz\n",
    "    img = np.pad(img, [[pad0 // 2, pad0 - pad0 // 2], [pad1 // 2, pad1 - pad1 // 2], [0, 0]],\n",
    "                 constant_values=255)\n",
    "    #     mask = np.pad(mask,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n",
    "    #                 constant_values=0)\n",
    "    img = img.reshape(img.shape[0] // sz, sz, img.shape[1] // sz, sz, 3)\n",
    "    img = img.transpose(0, 2, 1, 3, 4).reshape(-1, sz, sz, 3)\n",
    "    #     mask = mask.reshape(mask.shape[0]//sz,sz,mask.shape[1]//sz,sz,3)\n",
    "    #     mask = mask.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n",
    "    if len(img) < N:\n",
    "        #         mask = np.pad(mask,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=0)\n",
    "        img = np.pad(img, [[0, N - len(img)], [0, 0], [0, 0], [0, 0]], constant_values=255)\n",
    "    idxs = np.argsort(img.reshape(img.shape[0], -1).sum(-1))[:N]\n",
    "    img = img[idxs]\n",
    "    #     mask = mask[idxs]\n",
    "    av_blk = 0\n",
    "    for i in range(N):\n",
    "        ss = (img[i] < 240).sum()\n",
    "        if ss / sz / sz > 0.5:\n",
    "            av_blk += 1\n",
    "    img = np.array(img).reshape(sN, sN, sz, sz, 3).transpose(0, 2, 1, 3, 4).reshape(sN * sz, sN * sz, 3)\n",
    "    #     mask = np.array(mask).reshape(sN,sN,sz,sz,3).transpose(0,2,1,3,4).reshape(sN*sz,sN*sz,3)\n",
    "    #     for i in range(len(img)):\n",
    "    #         imgs.append(img)\n",
    "    #         result.append({'img':img[i], 'mask':mask[i], 'idx':i})\n",
    "    return img, av_blk\n",
    "\n",
    "\n",
    "class PANDA_dataset(Dataset):\n",
    "    def __init__(self, data_path=\"./data\", split=\"train\", valid_blocks=25, kfold=0, nfold=5, IMAGE_DIR=\"images_all\"):\n",
    "        super(PANDA_dataset, self).__init__()\n",
    "        self.split = split\n",
    "        self.path = data_path\n",
    "        self.data = []\n",
    "        self.valid_blocks = valid_blocks\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "        self.IMAGE_DIR = IMAGE_DIR\n",
    "        self.transform = albumentations.Compose([\n",
    "            albumentations.Transpose(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "        ])\n",
    "        if split == \"train\" or split == \"valid\":\n",
    "            with open(os.path.join(data_path, \"train.csv\"), 'r') as f:\n",
    "                csv_f = csv.DictReader(f)\n",
    "                for row in csv_f:\n",
    "                    self.data.append(\n",
    "                        [row['image_id'], row['data_provider'], int(row['isup_grade']), row['gleason_score']])\n",
    "            self.data_check()\n",
    "            self.data.sort()\n",
    "            valid_begin = int(len(self.data) / nfold * kfold)\n",
    "            valid_end = int(len(self.data) / nfold * (kfold + 1))\n",
    "            if split == \"valid\":\n",
    "                self.data = self.data[valid_begin:valid_end]\n",
    "                print(\"Using split = {}, data = [{} ... {}], size = {}.\".format(\n",
    "                    split, self.data[0][0], self.data[-1][0], len(self.data)))\n",
    "            else:\n",
    "                self.data = self.data[:valid_begin] + self.data[valid_end:]\n",
    "                print(\"Using split = {}, data = [{} ...(val)... {}], size = {}.\".format(\n",
    "                    split, self.data[0][0], self.data[-1][0], len(self.data)))\n",
    "        else:\n",
    "            print(os.path.join(self.path, self.IMAGE_DIR))\n",
    "            for root, dirs, files in os.walk(os.path.join(self.path, self.IMAGE_DIR)):\n",
    "                for file in files:\n",
    "                    self.data.append(file.split('.')[0])\n",
    "\n",
    "    def data_check(self):\n",
    "        missing = []\n",
    "        for x in self.data:\n",
    "            name = x[0]\n",
    "            if not os.path.exists(os.path.join(self.path, self.IMAGE_DIR, name + \".png\")):\n",
    "                missing.append(name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, x):\n",
    "        if self.split == \"test\":\n",
    "            x = self.data[x]\n",
    "            img = skimage.io.MultiImage(os.path.join(self.path, self.IMAGE_DIR, x + \".tiff\"))[1]\n",
    "            img, av_blk = tile(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            img = img.reshape(8, 256, 8, 256, 3).transpose(0, 2, 1, 3, 4).reshape(-1, 256, 256, 3)\n",
    "            img = img[0:self.valid_blocks]\n",
    "            img = img.reshape(-1, 256, 3).transpose(1, 0, 2)\n",
    "            img = self.toTensor(255 - img)\n",
    "            return img, x\n",
    "        else:\n",
    "            x = self.data[x]\n",
    "            img = cv2.imread(os.path.join(self.path, self.IMAGE_DIR, x[0] + \".png\"))\n",
    "            img = img.reshape(8, 256, 8, 256, 3).transpose(0, 2, 1, 3, 4).reshape(-1, 256, 256, 3)\n",
    "            weights = []\n",
    "            for i in range(img.shape[0]):\n",
    "                weights.append((img[i] < 240).sum() / 256 / 256 + 1e-5)  # [0.0 ~ 3.0]\n",
    "                if self.split == \"train\":\n",
    "                    img[i] = self.transform(image=img[i])[\"image\"]\n",
    "            weights = np.array(weights)\n",
    "            weights /= weights.sum()\n",
    "            idx = np.random.choice(np.arange(img.shape[0]), self.valid_blocks, p=weights, replace=False)\n",
    "            img = img[idx]\n",
    "            img = img.reshape(-1, 256, 3).transpose(1, 0, 2)\n",
    "            img = self.toTensor(255 - img)\n",
    "            return img, x[2]\n",
    "\n",
    "\n",
    "def build_data(batch_size, num_worker, **kwargs):\n",
    "    return DataLoader(PANDA_dataset(**kwargs), batch_size, shuffle=True,\n",
    "                      num_workers=num_worker)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "RANDOM_SEED = 1337\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def open_config(root):\n",
    "    f = open(os.path.join(root, \"config.yaml\"))\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    return config\n",
    "\n",
    "\n",
    "def load(models, epoch, root):\n",
    "    def _detect_latest():\n",
    "        checkpoints = os.listdir(os.path.join(root, \"logs\"))\n",
    "        checkpoints = [f for f in checkpoints if f.startswith(\"model-epoch-\") and f.endswith(\".pth\")]\n",
    "        checkpoints = [int(f[len(\"epoch-\"):-len(\".pth\")]) for f in checkpoints]\n",
    "        checkpoints = sorted(checkpoints)\n",
    "        _epoch = checkpoints[-1] if len(checkpoints) > 0 else None\n",
    "        return _epoch\n",
    "\n",
    "    if epoch == -1:\n",
    "        epoch = _detect_latest()\n",
    "    if epoch is None:\n",
    "        return -1\n",
    "    for name, model in models.items():\n",
    "        ckpt = torch.load(os.path.join(root, \"logs/ckpts/\" + name + \"_epoch-{}.pth\".format(epoch)))\n",
    "        ckpt = {k[7:]: v for k, v in ckpt.items()}\n",
    "        model.load_state_dict(ckpt)\n",
    "        print(\"load model: {} from epoch: {}\".format(name, epoch))\n",
    "    # print(\"loaded from epoch: {}\".format(epoch))\n",
    "    return epoch\n",
    "\n",
    "\n",
    "def test(args, root):\n",
    "    f = open(\"submission.csv\", \"w\", newline=\"\")\n",
    "    print(args)\n",
    "\n",
    "    args_data = args['data']\n",
    "    real_path=\"prostate-cancer-grade-assessment/test_images\"\n",
    "    dataloader = build_data(4, num_worker=4, data_path = \"/kaggle/input/\",split = \"test\", valid_blocks=args_data['valid_blocks'],\n",
    "                            IMAGE_DIR=real_path)\n",
    "    model = Resnet18_afix(N=args_data['valid_blocks'], pretrain=False).cuda()\n",
    "\n",
    "    load_epoch = load({\"model\": model}, 75, root)\n",
    "\n",
    "    preds = []\n",
    "    names = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (image, name) in tqdm(dataloader):\n",
    "            image = image.cuda()\n",
    "            fake = model(image)[0].round().int()\n",
    "            for i in range(len(name)):\n",
    "                names.append(name[i])\n",
    "                preds.append(fake[i].item())\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow((\"image_id\", \"isup_grade\"))\n",
    "    for i in range(len(names)):\n",
    "        writer.writerow((names[i], preds[i]))\n",
    "    print(preds)\n",
    "    f.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root=\"/kaggle/input/panda-exp-xwl/res18_fix\"\n",
    "#     root = \"./resnet18_5e5\"\n",
    "    test(open_config(root), root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}