{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "# plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
    "\n",
    "\n",
    "def show(i):\n",
    "    plt.imshow(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_small_dataset(path):\n",
    "    IMAGE_DIR = \"image_small\"\n",
    "    rows = []\n",
    "    with open(os.path.join(path, \"train.csv\"), 'r') as f:\n",
    "        csv_f = csv.DictReader(f)\n",
    "        for row in csv_f:\n",
    "            if os.path.exists(os.path.join(path, IMAGE_DIR, row['image_id'] + '.png')):\n",
    "                rows.append(row)\n",
    "    with open(os.path.join(path, \"train_small.csv\"), 'w') as f:\n",
    "        csv_f = csv.DictWriter(f, fieldnames=['image_id', 'data_provider', 'isup_grade', 'gleason_score'])\n",
    "        csv_f.writeheader()\n",
    "        for row in rows:\n",
    "            csv_f.writerow(row)\n",
    "\n",
    "generate_small_dataset('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_random_weighted_choice():\n",
    "    path = \"./data/image_small/0a0f8e20b1222b69416301444b117678.png\"\n",
    "    img = cv2.imread(path)\n",
    "    show(img)\n",
    "    img = img.reshape(8, 256, 8, 256, 3).transpose(0, 2, 1, 3, 4).reshape(-1, 256, 256, 3)\n",
    "    weights = []\n",
    "    for i in range(img.shape[0]):\n",
    "        w = (img[i] < 240).sum() / 256 / 256 + 1e-5\n",
    "        # print(w)\n",
    "        weights.append(w)\n",
    "    weights = np.array(weights)\n",
    "    weights /= weights.sum()\n",
    "    idx = np.random.choice(np.arange(img.shape[0]), 25, p=weights, replace=False)\n",
    "    print(\"choose index =\", sorted(idx))\n",
    "    img = img[idx]\n",
    "    img = img.reshape(5, 5, 256, 256, 3).transpose(0, 2, 1, 3, 4).reshape(5*256, 5*256, 3)\n",
    "    show(img)\n",
    "\n",
    "check_random_weighted_choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_builder import build_data\n",
    "from nets.base import widthN_to_bsN, bsN_to_widthN, Resnet18\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "def check_data_builder_and_model():\n",
    "    net = Resnet18().cuda()\n",
    "    for split in [\"train\", \"valid\"]:\n",
    "        dataloader = build_data('./data/', 2, split, num_worker=1, valid_block=25)\n",
    "        images, labels = next(iter(dataloader))\n",
    "        for i in images:\n",
    "            show(transforms.ToPILImage()(i))\n",
    "        \n",
    "        # (bs, 3, 256, 256*N) -> (N*bs, 3, 256, 256)\n",
    "        x = widthN_to_bsN(images, 25)\n",
    "        for i in torch.cat((x[:25][:2], x[25:][:2])):\n",
    "            show(transforms.ToPILImage()(i))\n",
    "        \n",
    "        # (N*bs, 3, 256, 256) -> (bs, 3, 256, 256*N)\n",
    "        x = bsN_to_widthN(x, 25)\n",
    "        for i in x:\n",
    "            show(transforms.ToPILImage()(i))\n",
    "\n",
    "        out = net(images.cuda())\n",
    "        print(out.shape)\n",
    "\n",
    "\n",
    "check_data_builder_and_model()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d3d76c264e12aa2fca2a0d0fe1ea040b4d6dec1adb785724b9f3e41731e9daa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
